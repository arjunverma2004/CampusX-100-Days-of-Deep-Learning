{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunverma2004/CampusX-100-Days-of-Deep-Learning/blob/main/Practice_code/Bach_chorales_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgPKI3d2vZUW"
      },
      "outputs": [],
      "source": [
        "!tar -xzf /content/jsb_chorales.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBr6YRHHw0Zh",
        "outputId": "72fb5a4b-1f0f-4281-8e22-5cb3ee45f327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 229 training chorales\n",
            "Loaded 76 validation chorales\n",
            "Loaded 77 test chorales\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Define the directory where the chorale files are located\n",
        "jsb_chorales_dir = \"/content/jsb_chorales\"\n",
        "\n",
        "# Find all CSV files within the subdirectories\n",
        "train_files = glob.glob(os.path.join(jsb_chorales_dir, \"train\", \"*.csv\"))\n",
        "valid_files = glob.glob(os.path.join(jsb_chorales_dir, \"valid\", \"*.csv\"))\n",
        "test_files = glob.glob(os.path.join(jsb_chorales_dir, \"test\", \"*.csv\"))\n",
        "\n",
        "def load_chorales(filepaths):\n",
        "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
        "\n",
        "train_chorales = load_chorales(train_files)\n",
        "valid_chorales = load_chorales(valid_files)\n",
        "test_chorales = load_chorales(test_files)\n",
        "\n",
        "print(f\"Loaded {len(train_chorales)} training chorales\")\n",
        "print(f\"Loaded {len(valid_chorales)} validation chorales\")\n",
        "print(f\"Loaded {len(test_chorales)} test chorales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aB59v9WxoAJ",
        "outputId": "b7669529-d0a1-45ad-c8de-57b28f8eabfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "229"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_chorales[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAbquTL1yC9H"
      },
      "outputs": [],
      "source": [
        "notes = set()\n",
        "for chorales in (train_chorales, valid_chorales, test_chorales):\n",
        "    for chorale in chorales:\n",
        "        for chord in chorale:\n",
        "            notes |= set(chord)\n",
        "\n",
        "n_notes = len(notes)\n",
        "min_note = min(notes - {0})\n",
        "max_note = max(notes)\n",
        "\n",
        "assert min_note == 36\n",
        "assert max_note == 81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poKpvpP3yVeX"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def notes_to_frequencies(notes):\n",
        "    # Frequency doubles when you go up one octave; there are 12 semi-tones\n",
        "    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n",
        "    return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
        "\n",
        "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
        "    note_duration = 60 / tempo # the tempo is measured in beats per minutes\n",
        "    # To reduce click sound at every beat, we round the frequencies to try to\n",
        "    # get the samples close to zero at the end of each note.\n",
        "    frequencies = (note_duration * frequencies).round() / note_duration\n",
        "    n_samples = int(note_duration * sample_rate)\n",
        "    time = np.linspace(0, note_duration, n_samples)\n",
        "    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
        "    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)\n",
        "    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
        "    return sine_waves.reshape(-1)\n",
        "\n",
        "def chords_to_samples(chords, tempo, sample_rate):\n",
        "    freqs = notes_to_frequencies(chords)\n",
        "    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n",
        "    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
        "                     for melody in freqs.T], axis=0)\n",
        "    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n",
        "    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
        "    merged[-n_fade_out_samples:] *= fade_out\n",
        "    return merged\n",
        "\n",
        "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
        "    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
        "    if filepath:\n",
        "        from scipy.io import wavfile\n",
        "        samples = (2**15 * samples).astype(np.int16)\n",
        "        wavfile.write(filepath, sample_rate, samples)\n",
        "        return display(Audio(filepath))\n",
        "    else:\n",
        "        return display(Audio(samples, rate=sample_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "saU9dFRuy7r1"
      },
      "outputs": [],
      "source": [
        "for index in range(3):\n",
        "    play_chords(train_chorales[index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "dhNkLES-0We5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pr41a2DSzJtm"
      },
      "outputs": [],
      "source": [
        "def create_target(batch):\n",
        "    X = batch[:, :-1]\n",
        "    Y = batch[:, 1:] # predict next note in each arpegio, at each step\n",
        "    return X, Y\n",
        "\n",
        "def preprocess(window):\n",
        "    window = tf.where(window == 0, window, window - min_note + 1) # shift values\n",
        "    return tf.reshape(window, [-1]) # convert to arpegio\n",
        "\n",
        "def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n",
        "                 window_size=32, window_shift=16, cache=True):\n",
        "    def batch_window(window):\n",
        "        return window.batch(window_size + 1)\n",
        "\n",
        "    def to_windows(chorale):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n",
        "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n",
        "        return dataset.flat_map(batch_window)\n",
        "\n",
        "    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n",
        "    dataset = dataset.flat_map(to_windows).map(preprocess)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(create_target)\n",
        "    return dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)\n",
        "valid_set = bach_dataset(valid_chorales)\n",
        "test_set = bach_dataset(test_chorales)"
      ],
      "metadata": {
        "id": "7m-M8Pvm02yu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embedding_dims = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,\n",
        "                           input_shape=[None]),\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_notes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "fDPGecWO07MD",
        "outputId": "d9fa5b9e-7b0d-4189-9b62-49e40102a0bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)        │           \u001b[38;5;34m235\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │         \u001b[38;5;34m3,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │           \u001b[38;5;34m192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │        \u001b[38;5;34m12,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m361,472\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)       │        \u001b[38;5;34m12,079\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">235</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">361,472</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,079</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m396,810\u001b[0m (1.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,810</span> (1.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,330\u001b[0m (1.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,330</span> (1.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "callback = EarlyStopping(monitor='loss', patience=3,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "mr_eJEwz1NII"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_set, epochs=200, validation_data=valid_set, callbacks=callback, initial_epoch=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFm1IaJq1Iv-",
        "outputId": "91db1ece-3905-42e8-b679-5addb7d1714c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7934a8550360>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     97/Unknown \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.9213 - loss: 0.2533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 27ms/step - accuracy: 0.9213 - loss: 0.2532 - val_accuracy: 0.8183 - val_loss: 0.6592\n",
            "Epoch 22/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9261 - loss: 0.2369 - val_accuracy: 0.8144 - val_loss: 0.6743\n",
            "Epoch 23/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9280 - loss: 0.2315 - val_accuracy: 0.8154 - val_loss: 0.6919\n",
            "Epoch 24/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9313 - loss: 0.2206 - val_accuracy: 0.8172 - val_loss: 0.6884\n",
            "Epoch 25/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9355 - loss: 0.2072 - val_accuracy: 0.8128 - val_loss: 0.7069\n",
            "Epoch 26/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9375 - loss: 0.2006 - val_accuracy: 0.8109 - val_loss: 0.7182\n",
            "Epoch 27/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9407 - loss: 0.1909 - val_accuracy: 0.8137 - val_loss: 0.7245\n",
            "Epoch 28/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9419 - loss: 0.1867 - val_accuracy: 0.8143 - val_loss: 0.7341\n",
            "Epoch 29/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.9440 - loss: 0.1787 - val_accuracy: 0.8120 - val_loss: 0.7432\n",
            "Epoch 30/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9464 - loss: 0.1721 - val_accuracy: 0.8114 - val_loss: 0.7510\n",
            "Epoch 31/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9486 - loss: 0.1631 - val_accuracy: 0.8095 - val_loss: 0.7724\n",
            "Epoch 32/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9495 - loss: 0.1601 - val_accuracy: 0.8104 - val_loss: 0.7840\n",
            "Epoch 33/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9513 - loss: 0.1547 - val_accuracy: 0.8068 - val_loss: 0.8036\n",
            "Epoch 34/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9477 - loss: 0.1630 - val_accuracy: 0.8082 - val_loss: 0.8086\n",
            "Epoch 35/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9534 - loss: 0.1478 - val_accuracy: 0.8106 - val_loss: 0.8037\n",
            "Epoch 36/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9554 - loss: 0.1411 - val_accuracy: 0.8093 - val_loss: 0.8179\n",
            "Epoch 37/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9561 - loss: 0.1391 - val_accuracy: 0.8084 - val_loss: 0.8299\n",
            "Epoch 38/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9581 - loss: 0.1332 - val_accuracy: 0.8082 - val_loss: 0.8458\n",
            "Epoch 39/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9583 - loss: 0.1315 - val_accuracy: 0.8082 - val_loss: 0.8464\n",
            "Epoch 40/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - accuracy: 0.9559 - loss: 0.1371 - val_accuracy: 0.8077 - val_loss: 0.8594\n",
            "Epoch 41/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9593 - loss: 0.1275 - val_accuracy: 0.8084 - val_loss: 0.8640\n",
            "Epoch 42/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9590 - loss: 0.1271 - val_accuracy: 0.8078 - val_loss: 0.8792\n",
            "Epoch 43/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9600 - loss: 0.1244 - val_accuracy: 0.8089 - val_loss: 0.8705\n",
            "Epoch 44/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9617 - loss: 0.1195 - val_accuracy: 0.8065 - val_loss: 0.8901\n",
            "Epoch 45/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - accuracy: 0.9601 - loss: 0.1246 - val_accuracy: 0.8005 - val_loss: 0.8995\n",
            "Epoch 46/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9209 - loss: 0.2316 - val_accuracy: 0.8061 - val_loss: 0.8717\n",
            "Epoch 47/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9589 - loss: 0.1264 - val_accuracy: 0.8099 - val_loss: 0.8752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x793460149f40>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6cLSSF2ICx",
        "outputId": "9d5ee308-ea27-4ec3-ea41-5088a0beea41"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8051 - loss: 0.8749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8848717212677002, 0.8053757548332214]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_chorale(model, seed_chords, length):\n",
        "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
        "    arpegio = tf.reshape(arpegio, [1, -1])\n",
        "    for chord in range(length):\n",
        "        for note in range(4):\n",
        "            next_note = model.predict(arpegio, verbose=0).argmax(axis=-1)[:1, -1:]\n",
        "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
        "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
        "    return tf.reshape(arpegio, shape=[-1, 4])"
      ],
      "metadata": {
        "id": "j0kY6G932pUi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_chords = test_chorales[2][:8]\n",
        "play_chords(seed_chords, amplitude=0.2)"
      ],
      "metadata": {
        "id": "0UTy0eCy25_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_chorale = generate_chorale(model, seed_chords, 56)\n",
        "play_chords(new_chorale)"
      ],
      "metadata": {
        "id": "YMcsiXvQ3YEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it's the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.\n",
        "\n",
        "So let's spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a temperature parameter that will control how \"hot\" (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones."
      ],
      "metadata": {
        "id": "TqdBypNI3f9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_chorale_v2(model, seed_chords, length, temperature=1):\n",
        "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
        "    arpegio = tf.reshape(arpegio, [1, -1])\n",
        "    for chord in range(length):\n",
        "        for note in range(4):\n",
        "            next_note_probas = model.predict(arpegio)[0, -1:]\n",
        "            rescaled_logits = tf.math.log(next_note_probas) / temperature\n",
        "            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
        "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
        "    return tf.reshape(arpegio, shape=[-1, 4])"
      ],
      "metadata": {
        "id": "UlxkZumz3d4j"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)\n",
        "play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")"
      ],
      "metadata": {
        "id": "zuzxK6013jPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)\n",
        "play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")"
      ],
      "metadata": {
        "id": "SHqx9Tos3z3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)\n",
        "play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")"
      ],
      "metadata": {
        "id": "7-EuOdF14Bk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM2Td4EmdoIGYAu7FVk7wk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}